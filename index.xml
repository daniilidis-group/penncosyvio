<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>PennCOSYVIO Data Set</title>
    <link>https://daniilidis-group.github.io/penncosyvio/</link>
    <description>Recent content on PennCOSYVIO Data Set</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Tue, 08 Mar 2016 21:07:13 +0100</lastBuildDate>
    <atom:link href="https://daniilidis-group.github.io/penncosyvio/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>The PennCOSYVIO Data Set</title>
      <link>https://daniilidis-group.github.io/penncosyvio/</link>
      <pubDate>Tue, 08 Mar 2016 21:07:13 +0100</pubDate>
      
      <guid>https://daniilidis-group.github.io/penncosyvio/</guid>
      <description>

&lt;h2 id=&#34;purpose&#34;&gt;Purpose&lt;/h2&gt;

&lt;p&gt;The PennCOSY VIO data set is collection of synchronized video and IMU data recorded at the University of Pennsylvania&amp;rsquo;s Singh Center in April 2016. It is geared towards benchmarking of Visual Inertial Odometry algorithms on hand-held devices, but can also be used for other platforms such as micro aerial vehicles or ground robots.&lt;/p&gt;

&lt;h2 id=&#34;features&#34;&gt;Features&lt;/h2&gt;

&lt;p&gt;What sets this benchmark apart from previous ones is that it goes from outdoors to indoors:
&lt;img src=&#34;pics/singh_outdoors_gopro.jpg&#34; alt=&#34;Singh Center from the outside&#34; /&gt;
&lt;img src=&#34;pics/singh_indoors_tango_rgb.jpg&#34; alt=&#34;inside the Singh Center&#34; /&gt;
and provides a fairly accurate ground truth (approx 10cm) for the camera rig:
&lt;img src=&#34;pics/sequence_as.jpg&#34; alt=&#34;sequence AS trajectory&#34; /&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Download</title>
      <link>https://daniilidis-group.github.io/penncosyvio/download/</link>
      <pubDate>Wed, 09 Mar 2016 00:11:02 +0100</pubDate>
      
      <guid>https://daniilidis-group.github.io/penncosyvio/download/</guid>
      <description>

&lt;h2 id=&#34;download&#34;&gt;Download&lt;/h2&gt;

&lt;p&gt;We are still working on this part &amp;hellip;. need to locate a large enough disk for hosting. Should happen any day.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Intrinsic Calibration</title>
      <link>https://daniilidis-group.github.io/penncosyvio/intrinsic_calib/</link>
      <pubDate>Wed, 09 Mar 2016 00:11:02 +0100</pubDate>
      
      <guid>https://daniilidis-group.github.io/penncosyvio/intrinsic_calib/</guid>
      <description>

&lt;p&gt;Two different models were used for the intrinsic calibration of the cameras:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://www.mathworks.com/help/vision/ug/camera-calibration.html&#34;&gt;standard perspective&lt;/a&gt;
model with two radial distortion distortion coefficients.
This model works well for the Tango Bottom RGB camera and the VI sensor cameras&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://sites.google.com/site/scarabotix/ocamcalib-toolbox&#34;&gt;omnidirectional model&lt;/a&gt; for
the GoPro cameras and the Tango Top. This is necessary to accurately
model the wide-angle lenses projection function all the way to the corners of the sensor.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;A square chessboard calibration target of 7x8 was used with square
length of 108mm. The images were cut from video, and are available
under the &lt;code&gt;intrinsic_calibration&lt;/code&gt; directory (requires separate download).&lt;/p&gt;

&lt;h2 id=&#34;how-to-use-the-calibration-models&#34;&gt;How to Use the Calibration Models&lt;/h2&gt;

&lt;p&gt;&lt;a name=&#34;howtousecalibmodels&#34;&gt;&lt;/a&gt;
The camera calibration models are stored under &lt;code&gt;dev/intrinsic_calibration/cc.mat&lt;/code&gt; and can be loaded
in Matlab like this:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;gt;&amp;gt; cd dev/matlab;
&amp;gt;&amp;gt; load ../intrinsic_calibration/cc.mat
&amp;gt;&amp;gt; cc

cc = 

    [1x1 struct]    [1x1 struct]    [1x1 struct]    [1x1 cameraParameters]    [1x1 struct]    [1x1 cameraParameters]    [1x1 cameraParameters]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The &lt;code&gt;cc&lt;/code&gt; cell array has the cameras in the order:
&lt;table&gt;
&lt;tr&gt;&lt;td&gt;1&lt;/td&gt;&lt;td&gt;2&lt;/td&gt;&lt;td&gt;3&lt;/td&gt;&lt;td&gt;4&lt;/td&gt;&lt;td&gt;5&lt;/td&gt;&lt;td&gt;6&lt;/td&gt;&lt;td&gt;7&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;GoPro C1&lt;/td&gt;&lt;td&gt;GoPro C2&lt;/td&gt;&lt;td&gt; GoPro C3&lt;/td&gt;&lt;td&gt; Tango Bottom&lt;/td&gt;&lt;td&gt; Tango Top&lt;/td&gt;&lt;td&gt;VI Sensor Left&lt;/td&gt;&lt;td&gt;VI Sensor Right&lt;/td&gt;&lt;/tr&gt;
&lt;/table&gt;&lt;/p&gt;

&lt;h3 id=&#34;undistorting-tango-bottom-and-vi-sensor-images&#34;&gt;Undistorting Tango Bottom and VI Sensor images&lt;/h3&gt;

&lt;p&gt;To undistort images for Tango Bottom&amp;rsquo;s RGB camera or the VI Sensors, you can directly use the Matlab &lt;code&gt;undistortImage&lt;/code&gt; function. The following matlab
line would read an image, undistort it with the Tango Bottom calibration parameters, and display it:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;gt;&amp;gt; imtool(undistortImage(imread(&#39;foo.jpg&#39;),cc{4}));
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;undistorting-gopro-and-tango-top-images&#34;&gt;Undistorting GoPro and Tango Top Images&lt;/h3&gt;

&lt;p&gt;&lt;a name=&#34;undistfisheye&#34;&gt;&lt;/a&gt;
Images taken with the fisheye lenses require the use of a custom undistortion matlab function for undistortion.
Undistortion is a two-step process: first a undistortion map is
pre-computed (this needs to be done only once per camera),
which then is used to perform the actual undistortion. For example, this would be the steps to undistort an image
for GoPro camera C1:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;gt;&amp;gt; u = ocam_undistort_map(cc{1}, &#39;OutputView&#39;, &#39;full&#39;);
&amp;gt;&amp;gt; imtool(ocam_undistort(imread(&#39;../../intrinsic_calibration/c1/frame_0011.png&#39;), u));
&lt;/code&gt;&lt;/pre&gt;

&lt;table&gt;
&lt;tr&gt;
&lt;td&gt;&lt;img alt=&#34;distorted original&#34; src=&#34;../pics/intcalib/c1_dist.jpg&#34;&gt;&lt;/td&gt;
&lt;td&gt;&lt;img alt=&#34;undistorted&#34; src=&#34;../pics/intcalib/c1_undist.jpg&#34;&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/table&gt;

&lt;p&gt;For more undistortion options, see &lt;code&gt;help ocam_undistort_map&lt;/code&gt;. In
particular setting &lt;code&gt;OutputView&lt;/code&gt; to &lt;code&gt;same&lt;/code&gt; is a useful choice, but you
can also increase the resolution to reduce quality loss during
undistort. Note that the intrinsic matrix $\cc{\mvec{K}}$ depends on the undistortion
mode used, and is in fact a field of the undistortion structure:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;gt;&amp;gt; u
u = 
    map: [2073600x2 double]
      K: [3x3 double]
    res: [1920 1080]
&amp;gt;&amp;gt; u.K&#39;
ans =
          472.402621799665                         0          958.773771858922
                         0          476.268511742695          539.250755510546
                         0                         0                         1
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;If instead &lt;code&gt;OutputView&lt;/code&gt; &lt;code&gt;same&lt;/code&gt; is used, the focal lengths will increase substantially!&lt;/p&gt;

&lt;h2 id=&#34;matlab-toolbox-tango-bottom-and-vi-sensors&#34;&gt;Matlab Toolbox: Tango Bottom and VI Sensors&lt;/h2&gt;

&lt;p&gt;We use Matlab&amp;rsquo;s built-in camera calibration tool, which uses the
camera model proposed by &lt;a href=&#34;http://www.vision.caltech.edu/bouguetj/calib_doc/&#34; title=&#34;Bouguet, J. Y.: Camera Calibration Toolbox for Matlab. Computational Vision at the California Institute of Technology.&#34;&gt;Bouguet&lt;/a&gt; for the CalTec Camera Calibration
Toolbox. The model consists of a perspective projection followed by a
radial distortion. For parsimony, we did not allow for skew or
tangential distortion, and limited the number of radial distortion
coefficients to two. This leads to the following model: the 3D point
$\cc{\cvec{X}{W}}$ in world coordinates is first transformed to the camera
frame by the current camera pose $\cc{\ctrans{T}{W}{C}}$:
$$
\cc{\vvec{x}{y}{z}=\ \cvec{X}{C}=\ \ctrans{T}{W}{C}\ \cvec{X}{W}}.
$$
Then, the projected 2D coordinates are obtained via:
$$
\cc{\vvt{x&amp;rsquo;}{y&amp;rsquo;} =\ \vvt{x/z}{y/z}}.
$$
Now the radial distortion is captured by:
$$
\cc{\vvt{x\dp}{y\dp} =\ \vvt{x&amp;rsquo;(1+k_1r&amp;rsquo;^2 +k_2r&amp;rsquo;^4)}{y&amp;rsquo;(1+k_1r&amp;rsquo;^2 +k_2r&amp;rsquo;^4)}},
$$
where $\cc{r&amp;rsquo;^2 = x&amp;rsquo;^2 + y&amp;rsquo;^2}$. Lastly, using the intrinsic matrix yields the sensor pixel coordinates:
$$
\cc{\vvt{u}{v} = \begin{bmatrix}f_x &amp;amp; 0 &amp;amp; c_x\\ 0 &amp;amp; f_y &amp;amp; c_y\end{bmatrix}\vvec{x\dp}{y\dp}{1}}.
$$&lt;/p&gt;

&lt;p&gt;Note that the camera models as stored in the Matlab cell array (see &lt;a href=&#34;#foo&#34;&gt;above&lt;/a&gt;) follow
Matlab convention, so their intrinsic matrix is transposed compared to the table below!
The VI sensor calibration is based off the rectified images (this explains why the radial distortion is virtually zero),
and is therefore the correct calibration to use for the rectified video frames in the ROS bag.&lt;/p&gt;

&lt;table&gt;
&lt;tr&gt;
&lt;td&gt;Camera&lt;/td&gt;&lt;td&gt;$\cc{\begin{bmatrix}f_x &amp; 0 &amp; c_x\\\ 0 &amp; f_y &amp; c_y\end{bmatrix}}$&lt;/td&gt;&lt;td&gt;$\cc{k_1}$&lt;/td&gt;&lt;td&gt;$\cc{k_2}$&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;Tango Bottom RGB&lt;/td&gt;&lt;td&gt;$\cc{\calmat{   1959.84}{   1959.39}{    981.87}{    524.94}}$&lt;/td&gt;&lt;td&gt; 0.21253&lt;/td&gt;&lt;td&gt;-0.46023&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;VI Sensor Left&lt;/td&gt;&lt;td&gt;$\cc{\calmat{    445.80}{    445.15}{    371.50}{    237.33}}$&lt;/td&gt;&lt;td&gt;-0.03671&lt;/td&gt;&lt;td&gt; 0.05260&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;VI Sensor Right&lt;/td&gt;&lt;td&gt;$\cc{\calmat{    445.75}{    445.23}{    369.28}{    238.72}}$&lt;/td&gt;&lt;td&gt;-0.03427&lt;/td&gt;&lt;td&gt; 0.04858&lt;/td&gt;&lt;/tr&gt;
&lt;/table&gt;

&lt;h2 id=&#34;fisheye-intrinsic-calibration-using-ocamcalib-toolbox&#34;&gt;Fisheye Intrinsic Calibration using OCamCalib Toolbox&lt;/h2&gt;

&lt;p&gt;We used the &lt;a href=&#34;https://sites.google.com/site/scarabotix/ocamcalib-toolbox/&#34; title=&#34;Scaramuzza, D: OCamCalib: Omnidirectional Camera Calibration Toolbox for Matlab.&#34;&gt;OCamCalib Toolbox&lt;/a&gt; (version 3.0) to fit a 4-parameter
polynomial to the forward projection function. The image center was
held fixed for parsimony, and because good results (less than 1px
average reprojection error) were obtained already without allowing the
center to float.&lt;/p&gt;

&lt;p&gt;Here the forward projection function of the GoPro Hero 4 camera
C2. Note that the horizontal FOV is twice the angle covered in the
graph (which is about 60 degrees).&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;../pics/intcalib/c2_projfun.jpg&#34; alt=&#34;forward projection function&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Here a graphical illustration of the different extrinsic positions that
were assumed, showing that we took images with the calibration target as
far in the corner as possible:
&lt;img src=&#34;../pics/intcalib/c2_ext.jpg&#34; alt=&#34;external calibration positions&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Below are the calibration parameters obtained from the toolbox. Refer
to &lt;a href=&#34;https://sites.google.com/site/scarabotix/ocamcalib-toolbox/&#34; title=&#34;Scaramuzza, D: OCamCalib: Omnidirectional Camera Calibration Toolbox for Matlab.&#34;&gt;2&lt;/a&gt; for description of the parameters and the camera model. The easiest way to use these numbers is
by loading the calibration data into Matlab as described &lt;a href=&#34;#howtousecalibmodels&#34;&gt;here&lt;/a&gt;. Note that there is no intrinsic camera matrix $\cc{\mvec{K}}$ in this table since $\cc{\mvec{K}}$ depends on the way in which the &lt;a href=&#34;#undistfisheye&#34;&gt;undistortion&lt;/a&gt; is done.&lt;/p&gt;

&lt;table&gt;
&lt;tr&gt;&lt;td&gt;Camera&lt;/td&gt;&lt;td&gt;width&lt;/td&gt;&lt;td&gt;height&lt;/td&gt;&lt;td&gt;xc&lt;/td&gt;&lt;td&gt;yc&lt;/td&gt;&lt;td&gt;c&lt;/td&gt;&lt;td&gt;d&lt;/td&gt;&lt;td&gt;e&lt;/td&gt;&lt;td&gt;ss [polynomial coefficients]&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;GoPro C1&lt;/td&gt;&lt;td&gt;1920&lt;/td&gt;&lt;td&gt;1080&lt;/td&gt;&lt;td&gt;540&lt;/td&gt;&lt;td&gt;960&lt;/td&gt;&lt;td&gt;1.008&lt;/td&gt;&lt;td&gt;$2.710\times 10^{-4}$&lt;/td&gt;&lt;td&gt;$2.158\times 10^{-4}$&lt;/td&gt;&lt;td&gt;$\cc{\begin{bmatrix}-867.43&amp;0&amp;3.113\times 10^{-4}&amp;5.142\times 10^{-8}&amp;2.253\times 10^{-11}\end{bmatrix}}$&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;GoPro C2&lt;/td&gt;&lt;td&gt;1920&lt;/td&gt;&lt;td&gt;1080&lt;/td&gt;&lt;td&gt;540&lt;/td&gt;&lt;td&gt;960&lt;/td&gt;&lt;td&gt;1.004&lt;/td&gt;&lt;td&gt;$2.989\times 10^{-4}$&lt;/td&gt;&lt;td&gt;$0.921\times 10^{-3}$&lt;/td&gt;&lt;td&gt;$\cc{\begin{bmatrix}-877.47&amp;0&amp;3.339\times 10^{-4}&amp;6.175\times 10^{-9}&amp;1.104\times 10^{-11}\end{bmatrix}}$&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;GoPro C3&lt;/td&gt;&lt;td&gt;1920&lt;/td&gt;&lt;td&gt;1080&lt;/td&gt;&lt;td&gt;540&lt;/td&gt;&lt;td&gt;960&lt;/td&gt;&lt;td&gt;1.006&lt;/td&gt;&lt;td&gt;$1.794\times 10^{-4}$&lt;/td&gt;&lt;td&gt;$5.722\times 10^{-4}$&lt;/td&gt;&lt;td&gt;$\cc{\begin{bmatrix}-875.98&amp;0&amp;3.358\times 10^{-4}&amp;2.055\times 10^{-8}&amp;2.877\times 10^{-11}\end{bmatrix}}$&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;Tango Top Fisheye&lt;/td&gt;&lt;td&gt;640&lt;/td&gt;&lt;td&gt;480&lt;/td&gt;&lt;td&gt;240&lt;/td&gt;&lt;td&gt;320&lt;/td&gt;&lt;td&gt;1.000&lt;/td&gt;&lt;td&gt;$4.162\times 10^{-4}$&lt;/td&gt;&lt;td&gt;$1.303\times 10^{-4}$&lt;/td&gt;&lt;td&gt;$\cc{\begin{bmatrix}-273.59&amp;0&amp;1.292\times 10^{-3}&amp;5.874\times 10^{-7}&amp;2.741\times 10^{-9}\end{bmatrix}}$&lt;/td&gt;&lt;/tr&gt;
&lt;/table&gt;
</description>
    </item>
    
    <item>
      <title>Extrinsic Calibration</title>
      <link>https://daniilidis-group.github.io/penncosyvio/extrinsic_calib/</link>
      <pubDate>Wed, 09 Mar 2016 00:11:02 +0100</pubDate>
      
      <guid>https://daniilidis-group.github.io/penncosyvio/extrinsic_calib/</guid>
      <description>

&lt;h2 id=&#34;rig-and-coordinate-system-conventions&#34;&gt;Rig and Coordinate System Conventions&lt;/h2&gt;

&lt;p&gt;&lt;img src=&#34;../pics/rig.jpg&#34; width=&#34;500&#34;&gt;
&lt;p&gt;All sensors are extrinsically calibrated with respect to the rig body (B) reference frame (which coincides with the center GoPro C2 camera).
For each sensor we give the transform $\cc{\mvec{T}}$ from the rig coordinate system to the sensor coordinate system. A left superscript indicates the coordinate system in which vectors are expressed, i.e. $\cc{\cvec{X}{C1}}$ are the coordinates of vector $\cc{X}$ in the reference frame of camera C1. The transform $\cc{\ctrans{T}{S1}{S2}}$ takes a vector expressed in coordinate system S1 and transforms it to system S2: $\cc{\cvec{X}{S2}=\ctrans{T}{S1}{S2}\ \cvec{X}{S1}}$. For example, given coordinates in the rig reference frame (B), the ones for camera C1 can be obtained via:
$$
\cc{\cvec{X}{C1}=\ctrans{T}{B}{C1}\ \cvec{X}{B}}
$$.&lt;/p&gt;

&lt;h2 id=&#34;transformations-in-matrix-form&#34;&gt;Transformations in Matrix Form&lt;/h2&gt;

&lt;p&gt;In the below table, the transform T can be expressed as a 3x4 transformation SE(3) matrix:
$$
\cc{\mvec{T}=\begin{bmatrix}\mvec{R}\ \mvec{t}\end{bmatrix}}
$$
where $\cc{\mvec{t}}$ is a 3x1 translation vector, and $\cc{\mvec{R}}$ is a 3x3 SO(3) rotation.
Note that $\cc{\mvec{t}}$ is expressed in meters, and is given in the coordinate system of the sensor.
&lt;/p&gt;

&lt;table&gt;
&lt;tr&gt;&lt;td&gt;Sensor&lt;/td&gt;&lt;td&gt;Transform&lt;/td&gt;&lt;td align=&#34;center&#34;&gt;$\cc{\begin{bmatrix}\mvec{R}\ \mvec{t}\end{bmatrix}}$&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;GoPro C1&lt;/td&gt;&lt;td&gt;$\cc{\ctrans{T}{B}{C1}}$&lt;/td&gt;&lt;td&gt;$\cc{\begin{bmatrix}    0.2961304418 &amp;    0.0011052645 &amp;    0.9551468682 &amp;    0.0827\\     0.0191451276 &amp;    0.9997915577 &amp;   -0.0070926152 &amp;    0.0025\\    -0.9549556144 &amp;    0.0203867479 &amp;    0.2960475553 &amp;   -0.1273\\ \end{bmatrix}}$&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;GoPro C2&lt;/td&gt;&lt;td&gt;$\cc{\ctrans{T}{B}{C2}}$&lt;/td&gt;&lt;td&gt;$\cc{\begin{bmatrix}    1.0000000000 &amp;    0.0000000000 &amp;    0.0000000000 &amp;    0.0000\\     0.0000000000 &amp;    1.0000000000 &amp;    0.0000000000 &amp;    0.0000\\     0.0000000000 &amp;    0.0000000000 &amp;    1.0000000000 &amp;    0.0000\\ \end{bmatrix}}$&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;GoPro C3&lt;/td&gt;&lt;td&gt;$\cc{\ctrans{T}{B}{C3}}$&lt;/td&gt;&lt;td&gt;$\cc{\begin{bmatrix}    0.2251883426 &amp;   -0.0049445900 &amp;   -0.9743027052 &amp;   -0.0396\\     0.0047482257 &amp;    0.9999808169 &amp;   -0.0039774600 &amp;   -0.0008\\     0.9743036820 &amp;   -0.0037305315 &amp;    0.2252075009 &amp;   -0.1570\\ \end{bmatrix}}$&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;Tango Bottom RGB&lt;/td&gt;&lt;td&gt;$\cc{\ctrans{T}{B}{TBR}}$&lt;/td&gt;&lt;td&gt;$\cc{\begin{bmatrix}    0.9986085337 &amp;    0.0027720771 &amp;   -0.0526622452 &amp;   -0.0684\\    -0.0079486091 &amp;    0.9951207697 &amp;   -0.0983436495 &amp;    0.0841\\     0.0521326778 &amp;    0.0986253992 &amp;    0.9937581268 &amp;    0.0440\\ \end{bmatrix}}$&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;Tango Top Fisheye&lt;/td&gt;&lt;td&gt;$\cc{\ctrans{T}{B}{TTF}}$&lt;/td&gt;&lt;td&gt;$\cc{\begin{bmatrix}    0.9995000221 &amp;    0.0130284988 &amp;   -0.0288090975 &amp;   -0.0147\\    -0.0128514581 &amp;    0.9998974312 &amp;    0.0063219540 &amp;    0.2082\\     0.0288885081 &amp;   -0.0059485542 &amp;    0.9995649398 &amp;   -0.0017\\ \end{bmatrix}}$&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;VI Sensor Left&lt;/td&gt;&lt;td&gt;$\cc{\ctrans{T}{B}{VL}}$&lt;/td&gt;&lt;td&gt;$\cc{\begin{bmatrix}    0.9991687124 &amp;   -0.0059124048 &amp;   -0.0403351908 &amp;    0.0427\\     0.0050322682 &amp;    0.9997477793 &amp;   -0.0218873038 &amp;   -0.1168\\     0.0404544240 &amp;    0.0216661317 &amp;    0.9989464542 &amp;   -0.0199\\ \end{bmatrix}}$&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;VI Sensor Right&lt;/td&gt;&lt;td&gt;$\cc{\ctrans{T}{B}{VR}}$&lt;/td&gt;&lt;td&gt;$\cc{\begin{bmatrix}    0.9990911633 &amp;   -0.0072415591 &amp;   -0.0420048470 &amp;   -0.0675\\     0.0063429185 &amp;    0.9997489915 &amp;   -0.0214877011 &amp;   -0.1165\\     0.0421499079 &amp;    0.0212017389 &amp;    0.9988863156 &amp;   -0.0201\\ \end{bmatrix}}$&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;Tango Bottom IMU&lt;/td&gt;&lt;td&gt;$\cc{\ctrans{T}{B}{TBI}}$&lt;/td&gt;&lt;td&gt;$\cc{\begin{bmatrix}    0.9986085337 &amp;    0.0027720770 &amp;   -0.0526622452 &amp;   -0.0070\\     0.0192066304 &amp;   -0.9491479460 &amp;    0.3142439848 &amp;   -0.0740\\    -0.0491131534 &amp;   -0.3148181892 &amp;   -0.9478804808 &amp;   -0.0588\\ \end{bmatrix}}$&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;Tango Top IMU&lt;/td&gt;&lt;td&gt;$\cc{\ctrans{T}{B}{TTI}}$&lt;/td&gt;&lt;td&gt;$\cc{\begin{bmatrix}    0.9995000221 &amp;    0.0130284988 &amp;   -0.0288090975 &amp;   -0.0033\\     0.0200390427 &amp;   -0.9658149773 &amp;    0.2584567012 &amp;   -0.2033\\    -0.0244569550 &amp;   -0.2589047853 &amp;   -0.9655931698 &amp;   -0.0498\\ \end{bmatrix}}$&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;VI Sensor IMU&lt;/td&gt;&lt;td&gt;$\cc{\ctrans{T}{B}{VI}}$&lt;/td&gt;&lt;td&gt;$\cc{\begin{bmatrix}    0.9989551739 &amp;   -0.0016800380 &amp;   -0.0456698809 &amp;   -0.0310\\     0.0005817624 &amp;    0.9997105684 &amp;   -0.0240508012 &amp;   -0.1257\\     0.0456970689 &amp;    0.0239991032 &amp;    0.9986670221 &amp;   -0.0171\\ \end{bmatrix}}$&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;Tango Bottom Pose&lt;/td&gt;&lt;td&gt;$\cc{\ctrans{T}{B}{TBP}}$&lt;/td&gt;&lt;td&gt;$\cc{\begin{bmatrix}    0.9986085337 &amp;    0.0027720770 &amp;   -0.0526622452 &amp;   -0.0070\\     0.0192066304 &amp;   -0.9491479460 &amp;    0.3142439848 &amp;   -0.0740\\    -0.0491131534 &amp;   -0.3148181892 &amp;   -0.9478804808 &amp;   -0.0588\\ \end{bmatrix}}$&lt;/td&gt;&lt;/tr&gt;
&lt;/table&gt;

&lt;h2 id=&#34;transformations-in-quaternion-form&#34;&gt;Transformations in Quaternion Form&lt;/h2&gt;

&lt;p&gt;The rotation matrix $\cc{\mvec{R}}$ is related to the unit
quaternion $\mq{q_w}{q_x}{q_y}{q_z}$ via:
$$
\cc{
\mathbf{R} = {\begin{pmatrix}
1 -2q_y^2-2q_z^2 &amp;amp; 2q_xq_y - 2q_zq_w &amp;amp; 2q_xq_z + 2q_yq_w\\
2q_xq_y + 2q_zq_w &amp;amp; 1 - 2q_x^2 -2 q_z^2 &amp;amp; 2q_yq_z -2 q_xq_w\\
2q_xq_z -2 q_yq_w &amp;amp; 2q_yq_z + 2 q_xq_w &amp;amp; 1-2q_x^2-2q_y^2\\
\end{pmatrix}}}
$$&lt;/p&gt;

&lt;table&gt;
&lt;tr&gt;&lt;td&gt;Sensor&lt;/td&gt;&lt;td&gt;Trans&lt;/td&gt;&lt;td align=&#34;center&#34;&gt;$\mq{q_w}{q_x}{q_y}{q_z}$&lt;/td&gt;&lt;td&gt;$\cc{\mvec{t}}$&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;GoPro C1&lt;/td&gt;&lt;td&gt;$\cc{\ctrans{T}{B}{C1}}$&lt;/td&gt;&lt;td&gt;$\mq{    0.8049797443}{    0.0085341784}{    0.5932144554}{    0.0056025829}$&lt;/td&gt;&lt;td&gt;$\nvec{    0.0827}{    0.0025}{   -0.1273}$&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;GoPro C2&lt;/td&gt;&lt;td&gt;$\cc{\ctrans{T}{B}{C2}}$&lt;/td&gt;&lt;td&gt;$\mq{    1.0000000000}{    0.0000000000}{    0.0000000000}{    0.0000000000}$&lt;/td&gt;&lt;td&gt;$\nvec{    0.0000}{    0.0000}{    0.0000}$&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;GoPro C3&lt;/td&gt;&lt;td&gt;$\cc{\ctrans{T}{B}{C3}}$&lt;/td&gt;&lt;td&gt;$\mq{    0.7826839497}{    0.0000788724}{   -0.6224116350}{    0.0030960184}$&lt;/td&gt;&lt;td&gt;$\nvec{   -0.0396}{   -0.0008}{   -0.1570}$&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;Tango Bottom RGB&lt;/td&gt;&lt;td&gt;$\cc{\ctrans{T}{B}{TBR}}$&lt;/td&gt;&lt;td&gt;$\mq{    0.9984347037}{    0.0493194617}{   -0.0262398038}{   -0.0026843734}$&lt;/td&gt;&lt;td&gt;$\nvec{   -0.0684}{    0.0841}{    0.0440}$&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;Tango Top Fisheye&lt;/td&gt;&lt;td&gt;$\cc{\ctrans{T}{B}{TTF}}$&lt;/td&gt;&lt;td&gt;$\mq{    0.9998702907}{   -0.0030680250}{   -0.0144262726}{   -0.0064708286}$&lt;/td&gt;&lt;td&gt;$\nvec{   -0.0147}{    0.2082}{   -0.0017}$&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;VI Sensor Left&lt;/td&gt;&lt;td&gt;$\cc{\ctrans{T}{B}{VL}}$&lt;/td&gt;&lt;td&gt;$\mq{    0.9997328325}{    0.0108912687}{   -0.0202028012}{    0.0027368995}$&lt;/td&gt;&lt;td&gt;$\nvec{    0.0427}{   -0.1168}{   -0.0199}$&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;VI Sensor Right&lt;/td&gt;&lt;td&gt;$\cc{\ctrans{T}{B}{VR}}$&lt;/td&gt;&lt;td&gt;$\mq{    0.9997157684}{    0.0106753943}{   -0.0210446703}{    0.0033970850}$&lt;/td&gt;&lt;td&gt;$\nvec{   -0.0675}{   -0.1165}{   -0.0201}$&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;Tango Bottom IMU&lt;/td&gt;&lt;td&gt;$\cc{\ctrans{T}{B}{TBI}}$&lt;/td&gt;&lt;td&gt;$\mq{   -0.1593581712}{    0.9868684006}{    0.0055677908}{   -0.0257824140}$&lt;/td&gt;&lt;td&gt;$\nvec{   -0.0070}{   -0.0740}{   -0.0588}$&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;Tango Top IMU&lt;/td&gt;&lt;td&gt;$\cc{\ctrans{T}{B}{TTI}}$&lt;/td&gt;&lt;td&gt;$\mq{   -0.1304720995}{    0.9913259011}{    0.0083392206}{   -0.0134330326}$&lt;/td&gt;&lt;td&gt;$\nvec{   -0.0033}{   -0.2033}{   -0.0498}$&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;VI Sensor IMU&lt;/td&gt;&lt;td&gt;$\cc{\ctrans{T}{B}{VI}}$&lt;/td&gt;&lt;td&gt;$\mq{    0.9996665399}{    0.0120164831}{   -0.0228493568}{    0.0005656387}$&lt;/td&gt;&lt;td&gt;$\nvec{   -0.0310}{   -0.1257}{   -0.0171}$&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;Tango Bottom Pose&lt;/td&gt;&lt;td&gt;$\cc{\ctrans{T}{B}{TBP}}$&lt;/td&gt;&lt;td&gt;$\mq{   -0.1593581712}{    0.9868684006}{    0.0055677908}{   -0.0257824140}$&lt;/td&gt;&lt;td&gt;$\nvec{   -0.0070}{   -0.0740}{   -0.0588}$&lt;/td&gt;&lt;/tr&gt;
&lt;/table&gt;

&lt;h2 id=&#34;extrinsic-calibration-method&#34;&gt;Extrinsic calibration method&lt;/h2&gt;

&lt;p&gt;The AprilTags on the north wall of the Singh Center were used as a calibration target. A total of 16 synchronized snapshots were cut from the video footage, and optical calibration was performed as described in a forthcoming paper. As an example, here is a picture of snapshot #4. The complete set of images is available for download, as well as the locations of the AprilTags in that area.
&lt;table&gt;
&lt;tr&gt;
&lt;td&gt;&lt;figure&gt;&lt;img src=&#34;../pics/extcalib/ec_vl.jpg&#34; width=&#34;500&#34;&gt;&lt;figcaption&gt;VI Sensor left&lt;/figcaption&gt;&lt;/figure&gt;&lt;/td&gt;
&lt;td&gt;&lt;figure&gt;&lt;img src=&#34;../pics/extcalib/ec_vr.jpg&#34; width=&#34;500&#34;&gt;&lt;figcaption&gt;VI Sensor right&lt;/figcaption&gt;&lt;/figure&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;figure&gt;&lt;img src=&#34;../pics/extcalib/ec_tb.jpg&#34; width=&#34;500&#34;&gt;&lt;figcaption&gt;Tango Bottom&lt;/figcaption&gt;&lt;/figure&gt;&lt;/td&gt;
&lt;td&gt;&lt;figure&gt;&lt;img src=&#34;../pics/extcalib/ec_tt.jpg&#34; width=&#34;500&#34;&gt;&lt;figcaption&gt;Tango Top&lt;/figcaption&gt;&lt;/figure&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;figure&gt;&lt;img src=&#34;../pics/extcalib/ec_c1.jpg&#34; width=&#34;500&#34;&gt;&lt;figcaption&gt;GoPro C1&lt;/figcaption&gt;&lt;/figure&gt;&lt;/td&gt;
&lt;td&gt;&lt;figure&gt;&lt;img src=&#34;../pics/extcalib/ec_c2.jpg&#34; width=&#34;500&#34;&gt;&lt;figcaption&gt;GoPro C2&lt;/figcaption&gt;&lt;/figure&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;figure&gt;&lt;img src=&#34;../pics/extcalib/ec_c3.jpg&#34; width=&#34;500&#34;&gt;&lt;figcaption&gt;GoPro C3&lt;/figcaption&gt;&lt;/figure&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/table&gt;&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>